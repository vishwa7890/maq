"""add session_uuid to chat_sessions

Revision ID: 2c9123594bb1
Revises: c4627fcd9959
Create Date: 2025-07-24 22:39:14.847293

"""
from typing import Sequence, Union

import uuid
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from sqlalchemy import text

# revision identifiers, used by Alembic.
revision: str = '2c9123594bb1'
down_revision: Union[str, Sequence[str], None] = 'c4627fcd9959'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    # Add columns as nullable first
    op.add_column('chat_messages', sa.Column('message_uuid', sa.String(length=36), nullable=True))
    op.add_column('chat_messages', sa.Column('metadata', sa.JSON(), nullable=True))
    
    # Generate UUIDs for existing messages
    conn = op.get_bind()
    messages = conn.execute(text("SELECT id FROM chat_messages")).fetchall()
    for message in messages:
        conn.execute(
            text("UPDATE chat_messages SET message_uuid = :uuid WHERE id = :id"),
            {'uuid': str(uuid.uuid4()), 'id': message[0]}
        )
    
    # Now alter the column to be NOT NULL
    op.alter_column('chat_messages', 'message_uuid', nullable=False)
    op.create_index(op.f('ix_chat_messages_message_uuid'), 'chat_messages', ['message_uuid'], unique=True)
    op.create_index(op.f('ix_chat_messages_timestamp'), 'chat_messages', ['timestamp'], unique=False)
    op.drop_constraint(op.f('fk_chat_messages_session'), 'chat_messages', type_='foreignkey')
    op.create_foreign_key(None, 'chat_messages', 'chat_sessions', ['session_id'], ['id'], ondelete='CASCADE')
    # Add session_uuid as nullable first
    op.add_column('chat_sessions', sa.Column('session_uuid', sa.String(length=36), nullable=True))
    
    # Generate UUIDs for existing sessions
    sessions = conn.execute(text("SELECT id FROM chat_sessions")).fetchall()
    for session in sessions:
        conn.execute(
            text("UPDATE chat_sessions SET session_uuid = :uuid WHERE id = :id"),
            {'uuid': str(uuid.uuid4()), 'id': session[0]}
        )
    
    # Now alter the column to be NOT NULL
    op.alter_column('chat_sessions', 'session_uuid', nullable=False)
    op.create_index(op.f('ix_chat_sessions_session_uuid'), 'chat_sessions', ['session_uuid'], unique=True)
    # Add document_uuid as nullable first
    op.add_column('documents', sa.Column('document_uuid', sa.String(length=36), nullable=True))
    
    # Generate UUIDs for existing documents
    documents = conn.execute(text("SELECT id FROM documents")).fetchall()
    for doc in documents:
        conn.execute(
            text("UPDATE documents SET document_uuid = :uuid WHERE id = :id"),
            {'uuid': str(uuid.uuid4()), 'id': doc[0]}
        )
    
    # Now alter the column to be NOT NULL
    op.alter_column('documents', 'document_uuid', nullable=False)
    op.add_column('documents', sa.Column('processing_error', sa.Text(), nullable=True))
    op.add_column('documents', sa.Column('page_count', sa.Integer(), nullable=True))
    op.add_column('documents', sa.Column('metadata', sa.JSON(), nullable=True))
    op.alter_column('documents', 'extracted_tables',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.create_index(op.f('ix_documents_document_uuid'), 'documents', ['document_uuid'], unique=True)
    op.create_index(op.f('ix_documents_processed'), 'documents', ['processed'], unique=False)
    op.create_index(op.f('ix_documents_uploaded_at'), 'documents', ['uploaded_at'], unique=False)
    op.drop_constraint(op.f('documents_session_id_fkey'), 'documents', type_='foreignkey')
    op.drop_constraint(op.f('documents_user_id_fkey'), 'documents', type_='foreignkey')
    op.create_foreign_key(None, 'documents', 'users', ['user_id'], ['id'], ondelete='CASCADE')
    op.create_foreign_key(None, 'documents', 'chat_sessions', ['session_id'], ['id'], ondelete='CASCADE')
    op.alter_column('pdf_comparisons', 'estimation_json',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('pdf_comparisons', 'mismatch_details',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('quote_interactions', 'interaction_metadata',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=True)
    op.alter_column('quotes', 'scope_of_work',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    op.alter_column('quotes', 'pricing',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=sa.JSON(),
               existing_nullable=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.alter_column('quotes', 'pricing',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('quotes', 'scope_of_work',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.alter_column('quote_interactions', 'interaction_metadata',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('pdf_comparisons', 'mismatch_details',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.alter_column('pdf_comparisons', 'estimation_json',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
    op.drop_constraint(None, 'documents', type_='foreignkey')
    op.drop_constraint(None, 'documents', type_='foreignkey')
    op.create_foreign_key(op.f('documents_user_id_fkey'), 'documents', 'users', ['user_id'], ['id'])
    op.create_foreign_key(op.f('documents_session_id_fkey'), 'documents', 'chat_sessions', ['session_id'], ['id'])
    op.drop_index(op.f('ix_documents_uploaded_at'), table_name='documents')
    op.drop_index(op.f('ix_documents_processed'), table_name='documents')
    op.drop_index(op.f('ix_documents_document_uuid'), table_name='documents')
    op.alter_column('documents', 'extracted_tables',
               existing_type=sa.JSON(),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
    op.drop_column('documents', 'metadata')
    op.drop_column('documents', 'page_count')
    op.drop_column('documents', 'processing_error')
    op.drop_column('documents', 'document_uuid')
    op.drop_index(op.f('ix_chat_sessions_session_uuid'), table_name='chat_sessions')
    op.drop_column('chat_sessions', 'session_uuid')
    op.drop_constraint(None, 'chat_messages', type_='foreignkey')
    op.create_foreign_key(op.f('fk_chat_messages_session'), 'chat_messages', 'chat_sessions', ['session_id'], ['id'])
    op.drop_index(op.f('ix_chat_messages_timestamp'), table_name='chat_messages')
    op.drop_index(op.f('ix_chat_messages_message_uuid'), table_name='chat_messages')
    op.drop_column('chat_messages', 'metadata')
    op.drop_column('chat_messages', 'message_uuid')
    # ### end Alembic commands ###
